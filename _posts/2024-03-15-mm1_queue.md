---
layout: single
title: "M/M/1 Queueing Theory"
categories: mathematics
tags: [probability, stochastic process]
use_math: true
publish: false
author_profile: false
toc: true
---

# 0. Overview

신호 최적화 쪽 일을 하다가 대기행렬이론(Queueing theory)이 접목된 식을 통해 모델링하는 과정이 있었습니다.
정확하게는 도착률(arrival rate)이 $\lambda$이고 출발률(departure rate)가 $\mu$인 M/M/1 대기행렬(queue)에서 대기행렬의 길이 (queue length) $N$의 평균이

$$\mathbb E[N] = \frac\rho{1-\rho}$$

라는 사실을 사용하게 되었습니다. (단, $\rho=\frac\lambda\mu<1$)
그래서 해당 이론인 M/M/1 대기행렬이론에 대해 공부하게 되었고 그 결과를 포스팅해봅니다.

학부에 다니면서는 확률 공부를 아예 하지 않았고, 대학원에 있으면서는 확률을 다루기는 했지만 큐잉이론은 공부할 일은 없었습니다.
다만, 이 분야를 전공하시는 교수님이 계셨기 때문에 queueing theory 라는 이름 자체에는 익숙했고, 대충 무슨 것을 하는 지는 알고 있었습니다.
그러다 작년, 확률론 일반을 공부하면서 Poisson process를 배우게 되었고, 그때 배웠던 것이 이번에 M/M/1 대기행렬 이론을 이해하는 데 큰 도움이 되었습니다.

주로 공부한 자료는 다음의 유튜브 영상입니다.

- [Queueing theory and Poisson process](https://youtu.be/rBIQmwaoZfs)

워낙 유튜브 영상에서 완벽하고 친절하게 M/M/1 queueing theory에 대해 설명하고 있어서, 별도로 포스팅을 하는 게 의미가 있을까 싶을 정도입니다.
하지만, 공부한 기록을 남기고 싶기도 하고, 해당 영상에서는 $\mathbb E[N]$ 식에 대한 증명까지는 하고 있지 않으므로, 포스팅을 남겨봅니다.

$\mathbb E[N]$ 식에 대한 증명은

- [Expected waiting time in M/M/1 queue](https://math.stackexchange.com/questions/3423366/expected-waiting-time-in-m-m-1-queue)

를 보고 해봤지만, 해당 글에 증명이 직접적으로 있지는 않습니다.

모든 논의는 Poisson process를 기반으로 합니다.
Poisson process에 대해서는 어느 정도 알고 있다고 자부했지만, 막상 글을 쓰려니 확실히 설명하기가 어려웠습니다.
[위키피디아](https://en.wikipedia.org/wiki/Poisson_point_process)에 개략적인 설명이 있고 [University of Münster 자료](https://www.uni-muenster.de/Stochastik/lehre/WS1314/BachelorWT/Daten/StPro_Ross1.pdf)에서는 axiomatic한 정의를 찾았지만,

- [Chapter2 : Poisson Processes (MIT 자료)](https://ocw.mit.edu/courses/6-262-discrete-stochastic-processes-spring-2011/3a19ce0e02d0008877351bfa24f3716a_MIT6_262S11_chap02.pdf)

가 가장 잘 설명되어 있기에 많이 참고했습니다.

# 1. Poisson Process

카페를 운영하고 있는 사장님이 손님을 기다리고 있습니다.
만약 10분에 한 명 꼴로 손님이 들어온다고 하면 손님이 카페에 들어오는 과정은 Poisson process로 모델링될 수 있습니다.

배달기사가 배달주문을 기다리고 있습니다.
1시간에 5번 꼴로 배달주문이 접수된다고 하면, 몇 분 후에 배달 일이 잡힐 지 하는 것도 Poisson process로 모델링될 수 있습니다.

이렇듯, 많은 자연현상 혹은 사회현상들이 Poisson process으로 해석될 수 있습니다.
정확하게는, 어떤 사건이 시간에 따라 반복적으로 일어날 수 있고, 사건이 일어날 것이라고 기대되는 정도가 이전의 사건 발생에 관계없이 일정하다고 가정될 때, Poisson process를 생각할 수 있습니다.

<div class="notice--info">
확률론에서 '사건'(event)이라는 말은 확률공간의 부분집합을 의미하지만, 이 글에서는 특정한 일이 발생하는 것을 '사건'이라고 썼습니다.
MIT 자료에서는 이러한 모호성을 방지하기 위해 event라는 단어 대신 arrival이라는 단어를 사용하고 있습니다.
</div>

## 1.1 Poisson process as a stochastic process

### 1.1.1 stochastic process

확률변수들의 집합(a collection of random variables)을 확률과정(stochastic process)라고 합니다.
즉, 공집합이 아닌 집합 $J$(index set)이 존재해서 모든 $j\in J$에 대하여 $X_j$가 확률변수이면

$$\{X_j:j\in J\}$$

를 확률과정이라고 합니다.

### 1.1.2 arrival process

어떤 사건(arrival)이 시간 $t\ge0$에 따라 반복적으로 일어나면 이것을 arrival process라고 부릅니다.
만약 사건이 시각 $S_1$, $S_2$, $S_3$, $\cdots$ 에서 일어난다면 다음과 같은 그림으로 arrival process의 상황을 표현할 수 있습니다.

![]({{site.url}}\images\2024-03-15-mm1_queue\Si.png){: .img-80-center}

사건이 일어나는 시점 $S_i$이 일정하게 결정되어 있지 않고 확률적으로 발생한다면, 각각의 실수 $S_i$는 확률변수로 해석될 수 있습니다.
따라서 arrival process는 확률변수 $S_i$들의 집합

$$\{S_i:i=1,2,3,\cdots\}\tag{1}$$

으로 표현될 수 있습니다.
이때의 index set은 자연수 집합입니다.

한편, 인접한 두 사건의 시간간격을 $X_i$라고 하면, 다시 말해

$$X_i=
\begin{cases}
S_i-S_{i-1} &(i>1)\\
S_1         &(i=1)
\end{cases}
$$

라고 하면, 그림으로는

![]({{site.url}}\images\2024-03-15-mm1_queue\Xi.png){: .img-80-center}

로 표현할 수 있을 것입니다.
그러면 $X_i$들도 확률변수라고 말할 수 있으므로 arrival process는 확률변수 $X_i$들의 집합

$$\{X_i:i=1,2,3,\cdots\}\tag{2}$$

으로도 표현될 수 있습니다.

또한, 특정한 시점 $t\ge0$에 대하여, 시각 $t$까지 사건이 발생한 횟수를 $N_t$라고 하면

![]({{site.url}}\images\2024-03-15-mm1_queue\Nt.png){: .img-80-center}

모든 $t\ge0$에 대하여 $N_t$는 확률변수입니다.
따라서 arrival process는 확률변수 $N_t$들의 집합

$$\{N_t:t\ge0,\cdots\}\tag{3}$$

으로도 표현될 수 있습니다.
이때의 index set은 양의 실수의 집합입니다.

다시 말해, arrival process는 확률과정으로 이해할 수 있는데 (1), (2), (3)의 서로 다른 세 방식의 확률과정으로 해석될 수 있는 것입니다.

![]({{site.url}}\images\2024-03-15-mm1_queue\three_stochastic_processes.png){: .img-80-center}

### 1.1.3 renewal process

어떤 arrival process에 대하여, 각각의 arrival이 독립적으로 발생하는 상황을 고려하는 것은 문제 상황을 간단하게 만들어줍니다.
조금 더 정확하게는, arrival들이 독립적이고, 각 arrival이 발생할 가능성이 동일한 경우(IID ; independent and identically distributed)를 renewal process라고 합니다.

즉, 어떤 arrival process에 대하여 $X_i$들이 독립적이고 확률분포가 같으면 이 process를 renewal process라고 말합니다.

## 1.2 Poisson process

$X_i$의 PDF가

$$f_{X_i}(x)=\lambda e^{-\lambda x}\quad(x\ge0)$$

로 주어지는 renewal process를 Poisson process라고 부릅니다.
이때, $\lambda\gt0$는 상수입니다.
이 분포를 지수분포(exponential distribution)라고 부르므로, Poisson process는 사건이 일어나는 시간의 간격이 지수분포를 이루는 경우를 말한다고 할 수 있습니다.

### 1.2.1 exponential distribution

Poisson process에서의 시간간격 $X_i$는 지수분포를 따른다고 했었습니다.
이때, 지수분포란, $X\ge0$에서 정의되는 연속확률분포로서

$$f_X(x)=\lambda e^{-\lambda x}\quad(x\gt0)\tag{4}$$

와 같은 PDF를 가지는 분포를 말합니다.
연속확률변수 $X$가 위와 같은 지수분포를 따르면 $X\sim\text{exponential}(\lambda)$로 표기하기도 합니다.

여기에서는 지수분포에 대한 기본적인 계산을 해봅니다.
먼저, $X$의 전체 확률은 1로 계산됩니다.

$$
\begin{align*}
P(X\ge0)
&=\int_0^\infty\lambda e^{-\lambda x}\,dx\\
&=\left[-e^{-\lambda x}\right]_0^\infty\\
&=0-(-1)\\
&=1
\end{align*}
$$

$X$의 CDF를 구해보면

$$
\begin{align*}
F_X(x)
&=P(X\le x)\\
&=\int_0^xf_X(x)\,dx\\
&=\int_0^x\lambda e^{-\lambda x}\,dx\\
&=\left[-e^{-\lambda x}\right]_0^x\\
&=(-e^{-\lambda x})-(-1)\\
&=1-e^{-\lambda x}
\end{align*}
\tag{5}
$$

이 됩니다.
$X$의 평균을 구해보면

$$
\begin{align*}
\mathbb E[X]
&=\int_0^\infty xf_X(x)\,dx\\
&=\int_0^\infty x\lambda e^{-\lambda x}\,dx\\
&=\left[-xe^{-\lambda x}\right]_0^\infty + \int_0^\infty e^{-\lambda x}\,dx\\
&=\left[(-0) - (-0)\right] + \left[-\frac1\lambda e^{-\lambda x}\right]_0^\infty\\
&=(-0)-\left(-\frac1\lambda\right)\\
&=\frac1\lambda
\end{align*}
$$

이 됩니다.

따라서, Poisson process에서 arrival이 발생하는 시간간격의 평균은 $\frac1\lambda$이고, $\lambda$는 arrival이 발생하는 평균빈도를 나타냅니다.

### 1.2.2 memoryless property

지수분포는 memoryless property라는 중요한 성질을 가집니다.

$X$가 연속확률변수일 때,
임의의 두 양수 $x_1$, $x_2$에 대하여 다음이 성립하면 $X$가 memoryless property를 가진다고 말합니다;

$$
\begin{align*}
P(X\gt x_1+x_2\vert X\gt x_2) = P(X\gt x_1)
\end{align*}
\tag{6}
$$

$X\gt x$는 $x$의 시간동안 사건이 발생하지 않았음을 의미합니다.
따라서, 위 식의 좌변은 $x_2$의 시간동안 사건이 발생하지 않았을 때, $x_1+x_2$의 시간동안 사건이 발생하지 않았음을 의미합니다.
그러면 위 식은 $x_2$의 시간동안 사건이 발생하지 않았다고 가정할 때, 그다음 $x_1$만큼의 시간동안 사건이 발생하지 않을 확률이, ($x_2$의 시간동안 사건이 발생하지 않았다는 가정 없이) $x_1$의 시간동안 사건이 발생하지 않을 확률과 같다는 것을 뜻합니다.
즉, 이전에 사건이 발생했건 발생하지 않았건 상관없이, 앞으로 $x_1$만큼의 시간동안 사건이 일어날 확률은 일정하다는 것입니다.

식 (6)은 조건부확률의 정의에 의해 다음 식과 동치입니다 ;

$$P(X\gt x_1+x_2)=P(X\gt x_1)P(X\gt x_2)$$

그리고 이 식은 식 (5)에 의해 쉽게 증명됩니다;

$$
\begin{align*}
P(X\gt x_1)P(X\gt x_2)
&=\left(1-F_X(x_1)\right)\left(1-F_X(x_2)\right)\\
&\stackrel{(5)}=e^{-\lambda x_1}e^{-\lambda x_2}\\
&=e^{-\lambda(x_1+x_2)}\\
&\stackrel{(5)}=1-F_X(x_1+x_2)\\
&=P(X\gt x_1+x_2)
\end{align*}
$$

흥미로운 것은, memoryless property를 가지는 유일한 연속확률분포가 지수분포라는 것입니다.
이에 대한 증명을 위해 연속확률변수 $X$가 memoryless property (6)을 가진다고 가정하고 $h(x)=\ln P(X\gt x)$로 두면,

$$
\begin{align*}
h(x_1+x_2)
&=\ln P(X\gt x_1+x_2)\\
&=\ln P(X\gt x_1)P(X\gt x_2)\\
&=\ln P(X\gt x_1) + \ln P(X\gt x_2)\\
&=h(x_1)+h(x_2)
\tag{7}
\end{align*}
$$

이 성립합니다.
그러면 수학적 귀납법에 의해서, 자연수 $n$에 대하여

$$
h(nx) = h(x+x+\cdots+x)=h(x)+h(x)+\cdots+h(x)=nh(x)
$$

입니다.
그러면, 자연수 $m$에 대하여

$$
mh\left(\frac1mx\right)=h(x)
$$

이 성립하고 이 식의 양변을 $m$으로 나누면

$$
h\left(\frac1mx\right)=\frac1m(x)
$$

가 됩니다.
따라서 유리수 $q=\frac nm\gt0$에 대하여

$$
h(qx)=h\left(n\cdot\frac1mx\right)=nh\left(\frac 1mx\right)=n\cdot\frac1mxh(x) = qh(x)
$$

입니다.
마지막으로 극한의 개념을 적절히 사용하면 실수 $c\gt0$에 대하여

$$h(cx)=ch(x)\tag{8}$$

임을 [증명](https://math.stackexchange.com/a/1664424/746048)할 수 있습니다.
식 (8)과 (9)에 의해, $h(x)$는 선형함수이고, 따라서

$$h(x)=\ln P(X\gt x)=kx$$

인 실수 $k$가 존재합니다.
$0\lt P(X\gt x)\lt1$
에서 $k\lt0$이므로 $k=-\lambda$로 두면 ($\lambda\gt0$)

$$P(X\gt x)=e^{-\lambda x}$$

가 성립합니다.
그러면

$$F_X(x) = 1-e^{-\lambda x}$$

이고 미분을 통해 

$$f_X(x)=\lambda e^{-\lambda x}$$

를 얻을 수 있습니다.
따라서, memoryless property를 가지는 유일한 연속확률분포는 지수분포임을 확인할 수 있습니다 $\square$.

### 1.2.3 Poisson distribution

Poisson process는 $X_i$가 지수분포를 따르는 경우를 말한다고 했습니다.
그런데 Poisson process는 세 종류의 확률변수 $S_i$, $X_i$, $N_t$로 표현될 수 있다고 했으므로, Poisson process의 상황은 다른 확률변수 $S_i$, $N_t$로도 묘사될 수 있습니다.
Poisson process에서의 $N_t$의 분포를 Poisson distribution이라고 합니다.

$X_i$

# 2. M/M/1 Queueing theory
