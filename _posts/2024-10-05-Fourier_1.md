---
layout: single
title: "1. The Genesis of Fourier Analysis"
categories: mathematics
tags: [analysis, Fourier analysis, Fourier Series]
use_math: true
publish: false
author_profile: false
toc:
  enabled: True
  level: 2
---

약 일년 반 전, 확률 및 통계 스터디를 하는 과정에서 Fourier analysis에 대해 잠시 공부한 적이 있었다.
당시 공부했던 것은 아주 완전히 입문용의, 그러니까 내가 이미 알고 있는 수준에서의 복습이었다.
그러니까 나는 지금도 Fourier series가 뭔지 어떤 형태가 있는지, Fourier transform이 뭔지 하는 것은 이미 알고 있다.
하지만 좀 제대로, 공신력있는 책의 텍스트를 따라가면서 공부하고 싶은 마음이 예전부터 있었다.

요즈음, 시간이 좀 난 김에 Stein의 *Fourier Analysis - an introduction*을 따라가며 공부하고 있다.
이 책의 1장부터 4장까지는 Fourier Series에 대한 내용이고, 5장부터 6장까지는 Fourier transform에 대한 내용이며, 7장은 Finite Fourier Analysis, 8장은 Dirichlet's Theorem에 대해 다루고 있는 것 같다.
나는 1장부터 읽어가고 있고, 이 포스트는 1장에 대한 기록이다.

1장의 제목은 "Genesis of Fourier Analsys"이고 각 절은 다음과 같은 순서로 되어 있다.
1. The vibrating string
2. The heat equation
3. Exercises
4. Problem

그러니 주 내용은 1절과 2절이다.
그런데 내용을 읽다보면, 본문에서는 다루지 않고 증명하지 않는 여러 기초적인 문제들이 있다.
이 문제는 당연히 3절에 위치해있다.
나는 이 포스트의 3절에 해당되는 문제들을 다 풀어보았다.
그리고 4절은 보지 않을 예정이다.

본문(1절과 2절)의 내용들은 잘 설명되어 있지만, 일부는 자세히 설명되어 있는 반면, 또 일부는 너무 많은 것들이 생략되어 설명되어 있다.
따라서 본문의 내용들을 적당히 요약하면서, 또 설명이 빠져있는 부분들은 채워가려 했다.
말하자면 rephrase했다고 할 수 있겠는데, 그런 작업이 내가 잘 이해하는 데에나, 아니면 내용을 정리하는 데에 도움이 되리라고 생각된다.

늘 그렇듯 품이 많이 드는 공부법이지만, 이렇게 정리해야 의미가 있을 거라고 생각된다.
본문을 이해하기 위해 A4용지에 계산한 많은 수식들이 모두 날아가기보다는 이렇게 블로그에 남아있는 편이 훨씬 더 나을 것이다.
다만, 예쁘게 쓰거나 문법에 맞게 쓰는 것보다는 일단 진도를 나가고 공부를 하는 것이 더 중요하므로, 오탈자를 자세히 검수하진 못할 것 같다.

<!--
# : chapter 단위. 각 md파일마다 하나씩만
- 1. chapter_title
## : section 단위.
- 1 section_title
### : subsection 단위 
- 1.1 subsection_title
#### : paragraph 단위
- Simple harmonic motion
-->

# Chapter 1. The Genesis of Fourier Series

## 1. The vibrating string

#### Simple harmonic motion

Consider a mass $m$ attached to a horizontal spring.
Let $y(t)$ be the displacement of the mass at time $t$ where the equilibrium position is set to $y=0$.
By Hooke's law and Newton's law,

$$-ky(t)=my''(t)$$

This becomes a simple ODE

$$y''(t)+c^2y(t)=0\tag1$$

where $c=\sqrt{\frac km}$.
By 3.6, the general solution of this ODE is

$$y(t)=a\cos ct+b\sin ct$$

Moreover, one could also write

$$y(t)=y(0)\cos ct+\frac{y'(0)}c\sin ct$$

or

$$y(t)=A\cos(ct-\phi).$$

#### Standing and traveling waves

One dimensional wave can be described as a function $y=u(x,t)$.
That is, we can specify the vertical displacement $y$ of a wave depending on the horizontal displacement $x$ and time $t$.
<!-- We can think of $u$ as a standing wave or a traveling wave. -->

A **standing wave** separates the variables $x$ and $t$ ;

$$u(x,t)=\phi(x)\psi(t)$$

Here, $\phi(x)$ represents a shape of the string while $\psi(t)$ represents an amplifying factor.

A **traveling wave** is

$$u(x,t)=F(x-ct).$$

Here, $F(x)$ is the initial profile of $u$.
This wave moves rightward if $c\gt0$ where $c$ can be thought of as the velocity.

#### Harmonic and superposition of tones

(quote without any modification) The pure tones are accompanied by combinations of overtones which are responsible for the timbre of the instrument.

### 1.1 Derivation of the wave equation

Consider a horizontal string of length $L$.
For sufficiently large integer $N$, subdivide the string into $N$ *particles* evenly.
$n$-th particle at $x=x_n=\frac nNL$ move vertically only.
And the only forces on the particle are the tensions from the neighboring particles ;

$$
\begin{aligned}
T_{\text{right}}&=\frac\tau h(y_{n+1}-y_n)\\
T_{\text{left}}&=\frac\tau h(y_{n-1}-y_n)
\end{aligned}
$$

Here, $\tau$ is a constant and $h=\frac LN$.
If $\rho$ is the length density of the string, which is uniform, then

$$
\begin{aligned}
\rho hy_n''(t)
&=\frac\tau h\left(y_{n+1}(t)+y_{n-1}(t)-2y_n(t)\right)\\
&=\frac\tau h\left(u(x_n+h,t)+u(x_n-h,t)-2u(x_n,t)\right)\\
\end{aligned}\tag2
$$

Dividing $h$ on both side and applying 3.8 by $h\to0$, we get $\rho y_n''(t)=\tau u_{xx}(x_n,t)$.
Now by $N\to\infty$,

$$\rho\frac{\partial^2 u}{\partial t^2}=\tau\frac{\partial^2 u}{\partial x^2}.\qquad(0\le x\le L)$$

This relation is known as the one-dimensional **wave equation**.<!-- Here $\rho$ and $\tau$ are positive constants. -->
Instead of considering the above general equation, we can think of the following standard equation

$$
\frac{\partial^2 u}{\partial t^2}=\frac{\partial^2 u}{\partial x^2}
.\qquad(0\le x\le \pi)
$$

We analyze and solve the standard one and simply apply change of variables for the general cases.

### 1.2 Solution to the wave equation

<!-- There are two kinds of solution to the wave equation ; -->
We can get two kinds of solution to the wave equation ;
(1) using traveling waves
(2) using the superposition of standing waves

#### A solution using traveling waves

Consider a physical problem of a string where $0\le x\le \pi$ :

$$
\begin{aligned}
\frac{\partial^2 u}{\partial t^2}=\frac{\partial^2 u}{\partial x^2}
& \qquad(\text{wave equation})\\
u(x,0)=f(x)
& \qquad(\text{the initial shape of the string})\\
\frac{\partial}{\partial t}u(x,0)=g(x)
& \qquad(\text{the initial velocity of the string})\\
u(0,t)=u(\pi,t)=0
& \qquad(\text{the string has fixed endpoints})
\end{aligned}
\tag a
$$

We claim that (a) has the general solution of the form

$$
u(x,t) = \frac12\left[f(x+t)+f(x-t)\right]+\frac12\int_{x-t}^{x+t}g(y)\,dy.
\tag b
$$

Note that $f$ and $g$ were a function only on the interval $[0,\pi]$ in (a).
Now in the above solution (b), $f$ and $g$ are defined everywhere in $\mathbb R$.
That is, we conceive $f$ and $g$ as an extended versions in (b).
From (a), extend the domain $[0,\pi]$ to $[-\pi, \pi]$ by defining $f(-x)=-f(x)$ and $g(-x)=-g(x)$ and then extend the domains to $\mathbb R$ by defining $f(x+2\pi)=f(x)$ and $g(x+2\pi)=g(x)$.
That is, $f$ and $g$ are periodic functions of period $2\pi$.
In order for $f$ and $g$ to be continuous, we need the conditions $f(0)=f(\pi)=0$ and $g(0)=g(\pi)=0$, which are guaranteed to be true from the original problem (a).

Before proving that (b) is a general solution of (a), i.e. (a) $\Rightarrow$ (b), let's check if (b) is a specific solution of (a), i.e. (b) $\Rightarrow$ (a).
By direct calculations,

$$
\begin{align*}
u_{tt}&=\frac12\left[f''(x+t)+f''(x-t)\right]+\frac12\left[g'(x+t)-g'(x-t)\right]\,dy\\
u_{xx}&=\frac12\left[f''(x+t)+f''(x-t)\right]+\frac12\left[g'(x+t)-g'(x-t)\right]\,dy
\end{align*}
$$

and the wave equation holds.
Moreover, since

$$
\begin{align*}
u(x,0)&=f(x)+0\\
u_t(x,0)&=0+g(x),
\end{align*}
$$

the initial conditions also hold.
For the boundary conditions, first note that
$f(\pi-s)=-f(-\pi+s)=-f(\pi+s)$
and
$g(\pi-s)=-g(-\pi+s)=-g(\pi+s)$ for real $s$.
Then

$$
\begin{align*}
u(0,t)
&=\frac12\left[f(t)+f(-t)\right]+\frac12\int_{-t}^tg(y)\,dy\\
&=0\\
u(\pi,t)&=\frac12\left[f(\pi+t)+f(\pi-t)\right]+\frac12\int_{\pi-t}^{\pi+t}g(y)\,dy\\
&=0.
\end{align*}
$$

Thus (a) holds provided (b).

<!-- Before proving (a) $\Rightarrow$ (b), suppose only  -->

Now consider (a) $\Rightarrow$ (b).
Let $\xi=x+t$ and $\eta=x-t$.
By the chain rule,

$$
\begin{aligned}
\frac{\partial u}{\partial t}
&=\frac{\partial\xi}{\partial t}\frac{\partial u}{\partial\xi}
+\frac{\partial\eta}{\partial t}\frac{\partial u}{\partial\eta}\\
&=\frac{\partial u}{\partial\xi} - \frac{\partial u}{\partial\eta}\\
\frac{\partial^2 u}{\partial t^2}
&=\frac{\partial\xi}{\partial t}\frac{\partial}{\partial\xi}
\left(\frac{\partial u}{\partial\xi} - \frac{\partial u}{\partial\eta}\right)
+\frac{\partial\eta}{\partial t}\frac{\partial}{\partial\eta}
\left(\frac{\partial u}{\partial\xi} - \frac{\partial u}{\partial\eta}\right)\\
&=\frac{\partial^2 u}{\partial\xi^2}
+\frac{\partial^2 u}{\partial\eta^2}
-2\frac{\partial^2 u}{\partial\xi\partial\eta}\\
\frac{\partial u}{\partial x}
&=\frac{\partial\xi}{\partial x}\frac{\partial u}{\partial\xi}
+\frac{\partial\eta}{\partial x}\frac{\partial u}{\partial\eta}\\
&=\frac{\partial u}{\partial\xi} + \frac{\partial u}{\partial\eta}\\
\frac{\partial^2 u}{\partial t^2}
&=\frac{\partial\xi}{\partial x}\frac{\partial}{\partial\xi}
\left(\frac{\partial u}{\partial\xi} + \frac{\partial u}{\partial\eta}\right)
+\frac{\partial\eta}{\partial x}\frac{\partial}{\partial\eta}
\left(\frac{\partial u}{\partial\xi} + \frac{\partial u}{\partial\eta}\right)\\
&=\frac{\partial^2 u}{\partial\xi^2}
+\frac{\partial^2 u}{\partial\eta^2}
+2\frac{\partial^2 u}{\partial\xi\partial\eta}.
\end{aligned}
$$

Equating $\frac{\partial^2 u}{\partial x^2}$ and $\frac{\partial^2 u} {\partial t^2}$ (wave equation), we have

$$\frac{\partial^2 u}{\partial\xi\partial\eta}=0$$

Write $u(x,t)=v(\xi,\eta)$, this is

$$\frac{\partial}{\partial\xi}\frac{\partial}{\partial\eta}v(\xi,\eta)=0$$

For any $\xi$, there exists $\zeta$ between $0$ and $\xi$ such that

$$
\frac{\frac{\partial}{\partial\eta}v(\xi,\eta) - \frac{\partial}{\partial\eta}v(0,\eta)}{\xi}=
\frac{\partial}{\partial\xi}\frac{\partial}{\partial\eta}v(\zeta,\eta)=0
$$

by the mean value theorem.
Denote $F(\eta)=v(0,\eta)$.
Then, $\frac{\partial}{\partial\eta}v(\xi,\eta) = F'(\eta)$.
That is, $\eta\mapsto v(\xi,\eta)$ and $\eta\mapsto F(\eta)$ have the same derivative.
Therefore, they differ by constant (with respect to $\eta$);

$$v(\xi, \eta)=F(\eta)+G(\xi).$$

In summary,

$$u(x, t)=F(x+t)+G(x-t).$$

for some twice differentiable functions $F$ and $G$.

Now by the initial conditions,

$$
\begin{aligned}
f(x)& = u(x,0) = F(x)+G(x)\\
g(x)& = u_t(x,0) = F'(x)-G'(x)
\end{aligned}
$$

Differentiate the first equation and use it to add or substract to the second, to get

$$
\begin{aligned}
F'(x)&=\frac12\left[f'(x)+g(x)\right]\\
G'(x)&=\frac12\left[f'(x)-g(x)\right]
\end{aligned}
$$

Thus,

$$
\begin{aligned}
F(x)
&=\int_0^x\frac12\left[f'(y)+g(y)\right]\,dy+C_1\\
&=\frac12f(x)+\frac12\int_0^xg(y)\,dy+C_1'\\
G(x)
&=\int_0^x\frac12\left[f'(y)-g(y)\right]\,dy+C_2\\
&=\frac12f(x)-\frac12\int_0^xg(y)\,dy+C_2'.
\end{aligned}
$$

Note that $C_1'+C_2'=0$ since $f(x)=F(x)+G(x)$.
Therefore,

$$
\begin{align*}
u(x,t)
&=F(x+t)+G(x-t)\\
&=\frac12f(x+t)+\frac12\int_0^{x+t}g(y)\,dy+C_1'
+\frac12f(x-t)-\frac12\int_0^{x-t}g(y)\,dy+C_2'\\
&=\frac12\left[f(x+t)+f(x-t)\right]+\frac12\int_{x-t}^{x+t}g(y)\,dy.
\end{align*}
$$

## 2. The Heat Equation

## 3. Exercises

### 3.1
The absolute value of $z=x+iy$ where $x,y\in\mathbb R$ is

$$|z| = \sqrt{x^2+y^2}.$$

(a) Geometrically, we can think of $z$ as a point $(x,y)$ in the plane $\mathbb R^2$.
In this sense, $|z|$ is the distance between two points $(0,0)$ and $(x,y)$.

(b) If $\vert z\vert=0$, then $z=0$.

Suppose that $\sqrt{x^2+y^2}=0$.
It follows that $x^2+y^2=0$ and $x=y=0$.
Thus $z=0$.

(c) If $\lambda\in\mathbb R$, then $\vert\lambda z\vert=\vert\lambda\vert\vert z\vert$.

$$|\lambda z|=|\lambda x + i(\lambda y)|
=\sqrt{\lambda^2x^2+\lambda^2y^2}
=|\lambda|\sqrt{x^2+y^2}
=|\lambda||z|.$$

(d) $\lvert z_1z_2\rvert=\lvert z_1\rvert\lvert z_2\rvert,\quad\lvert z_1+z_2\rvert\le\lvert z_1\rvert+\lvert z_2\rvert$

Since

$$
\begin{align*}
|z_1z_2|^2
&=\left|(x_1+iy_1)(x_2+iy_2)\right|^2\\
&=\left|(x_1x_2-y_1y_2)+i(x_1y_2+x_2y_1)\right|^2\\
&=(x_1x_2-y_1y_2)^2+(x_1y_2+x_2y_1)^2\\
&={x_1}^2{x_2}^2+{y_1}^2{y_2}^2+{x_1}^2{y_2}^2+{y_1}^2{x_2}^2\\
&=\left({x_1}^2+{y_1}^2\right)\left({x_2}^2+{y_2}^2\right)\\
&=|z_1|^2|z_2|^2,
\end{align*}
$$

It follows that $\lvert z_1z_2\rvert=\lvert z_1\rvert\lvert z_2\rvert$.

The second statement is equivalent to the following inequalities ;

$$
\begin{align*}
\left(|z_1|+|z_2|\right)^2&\ge|z_1+z_2|^2\\
\left(\sqrt{~{x_1}^2+{y_1}^2}+\sqrt{~{x_2}^2+{y_2}^2}\right)^2&\ge(x_1+x_2)^2+(y_1+y_2)^2\\
2\sqrt{~{x_1}^2+{y_1}^2}\sqrt{~{x_2}^2+{y_2}^2}&\ge2x_1x_2+2y_1y_2\\
\left({x_1}^2+{y_1}^2\right)\left({x_2}^2+{y_2}^2\right)&\ge\left(x_1x_2+y_1y_2\right)^2\\
\left(x_1y_2-x_2y_1\right)^2&\ge0\\
\end{align*}
$$

Since the last inequality holds for every $z_1$ and $z_2$, the original statement also holds for every $z_1$ and $z_2$.

(e) If $z\ne0$, then $\lvert1/z\rvert=1/\lvert z\rvert$

$$
\begin{align*}
\left|\frac 1z\right|
&=\left|\frac 1{x+iy}\right|\\
&=\left|\frac {x-iy}{x^2+y^2}\right|\\
&=\frac1{x^2+y^2}|x-iy|\\
&=\frac1{x^2+y^2}\sqrt{x^2+y^2}\\
&=\frac1{\sqrt{x^2+y^2}}\\
&=\frac1{|z|}
\end{align*}
$$

### 3.2
The complex conjugate of $z=x+iy$ is

$$\bar z = x-iy.$$

(a) Geometrically, $\bar z$ is the reflected point $(x,-y)$ of the original point $(x,y)$ through the x-axis.

(b) $\lvert z\rvert^2=z\bar z$

$$z\bar z = (x+iy)(x-iy)=x^2-(iy)^2=x^2+y^2=|z|^2$$

(c) If $z$ belongs to the unit circle, then $1/z=\bar z$.

Since $\lvert z\rvert=1$, we have $z\bar z=\lvert z\rvert^2=1$, where we can divide $z$ on both sides.

### 3.3
(a)
A complex sequence $\\{w_n\\}_{n=1}^\infty$ converges to $w$ or $w_n\to w$ if

$$\lim_{n\to\infty}|w_n-w|=0.$$

Show that the limit is unique.

Suppose that $w_n\to w$ and $w_n\to w'$ where $w\ne w'$.
Since $\frac{|w-w'|}3>0$, there exists $N$ and $N'$ such that

$$
\begin{align*}
n>N&\quad\Longrightarrow\quad|w_n-w|<\frac{|w-w'|}3\\
n>N'&\quad\Longrightarrow\quad|w_n-w'|<\frac{|w-w'|}3\\
\end{align*}
$$

Now if $n>\max(N,N')$, then

$$
\begin{align*}
|w-w'|
&\le\left|w_n-w\right|+\left|w_n-w'\right|\\
&\lt\frac{|w-w'|}3 + \frac{|w-w'|}3\\
&=\frac{2|w-w'|}3
\end{align*}
$$

It follows that $|w-w'|<0$.
This contradiction implies that the limit is unique.

(b) Prove that $\\{w_n\\}$ is Cauchy iff it is convergent.

Suppose that $\\{w_n\\}$ is convergent, say, to $w$.
Fix $\epsilon>0$.
Take $N$ so that

$$
n>N\quad\Longrightarrow\quad |w_n-w|<\frac\epsilon2.
$$

If $m>n>N$, then

$$
|w_m-w_n|\le|w_m-w|+|w_n-w|<\frac\epsilon2+\frac\epsilon2=\epsilon.
$$

It follows that $\\{w_n\\}$ is Cauchy.

Suppose on the contrary that $\\{w_n\\}$ is Cauchy.
Writing $w_n=x_n+iy_n$, it is immediate that $\\{x_n\\}$ and $\\{y_n\\}$ are also Cauchy.
Since $\mathbb R$ is complete, $\\{x_n\\}$ and $\\{y_n\\}$ are convergent, say, to $x$ and $y$, respectively.
Fix $\epsilon>0$.
There exists $N$ such that if $n>N$, then

$$
\begin{align*}
|x_n-x|&<\frac{\epsilon}2\\
|y_n-y|&<\frac{\epsilon}2\\
\end{align*}
$$

It follows that 

$$
\begin{align*}
|w_n-w|
&=\left|(x_n-x)+i(y_n-y)\right|\\
&\le|x_n-x|+|i(y_n-y)|\\
&=|x_n-x|+|y_n-y|\\
&<\epsilon.
\end{align*}
$$

Thus, $w_n\to w$.

(c) [Comparison Test] A series $\sum_{n=1}^\infty z_n$ converges if the partial sums

$$S_N = \sum_{n=1}^Nz_n$$

converges.

Prove that if $\\{a_n\\}$ is a nonnegative sequence whose series $\sum a_n$ converges such that $\lvert z_n\rvert\le a_n$ for all $n$, then $\sum z_n$ also converges.

<!-- It is enough to prove that for any $\epsilon>0$, there exists $N>0$ such that if $m>n>N$, then

$$\left|S_m-S_n\right|<\epsilon.$$

Note that $S_m-S_n=\sum_{i=n+1}^mz_n$. -->

Fix $\epsilon\gt0$.
Since $\sum a_n$ converges, the partial sum of $\\{a_n\\}$ converges and is Cauchy.
Thus, there exists $N>0$ such that if $m>n>N$, then

$$
\sum_{i=n+1}^ma_n <\epsilon.
$$

Then, if $m>n>N$,

$$
|S_m-S_n|=\left|\sum_{i=n+1}^mz_n\right| \le \sum_{i=n+1}^m|z_n| \le \sum_{i=n+1}^ma_n <\epsilon.
$$

Therefore, the $\\{S_n\\}$ is Cauchy and is convergent.
It follows that $\sum z_n$ converges.

### 3.4
Define the exponential function as a power series as follows ;

$$
e^z=\sum_{n=0}^\infty\frac{z^n}{n!}
$$

(a) Prove that the above sum is always convergent.
Moreover show that the convergence is uniform on every bounded subset $S$ of $\mathbb C$.

Fix $z\in C$ and apply the ratio test;

$$
\lim_{n\to\infty}\frac{\frac{z^{n+1}}{(n+1)!}}{\frac{z^n}{n!}}
=\lim_{n\to\infty}\frac{z}{n+1}=0.
$$

Thus, the power series is convergent.

Now, exclude the case when $S=\varnothing$.
Let $M=\sup\\{|s|:s\in S\\}$ so that $0\le M<\infty$.
Denote

$$f_n(z)=\sum_{k=1}^n\frac{z^k}{k!}.$$

We know that $f_n\to f$ pointwisely where $f(z)=e^z$, and we are to prove that $f_n\to f$ uniformly.

Fix $\epsilon>0$.
Note that the summation

$$\sum_{n=0}^\infty\frac{M^n}{n!}$$

converges by another ratio test.
That is, there exists $N$ such that if $m>n>N$, then

$$
\sum_{k=n+1}^m\frac{M^k}{k!}<\epsilon.
$$

Now, if $z\in S$ and $m>n>N$, then

$$
\begin{align*}
\left|f_m(z)-f_n(z)\right|
&=\left|\sum_{k=n+1}^m\frac{z^k}{k!}\right|\\
&\le\sum_{k=n+1}^m\frac{|z|^k}{k!}\\
&\le\sum_{k=n+1}^m\frac{M^k}{k!}\\
&<\epsilon.
\end{align*}
$$

That is, $\\{f_n\\}$ is Cauchy and thus convergent.

With the $N$ corresponding to the $\epsilon>0$, if $n>N$ and $z\in S$, then

$$
\begin{align*}
\left|f(z)-f_n(z)\right|
&=\left|\lim_{m\to\infty}f_m(z)-f_n(z)\right|\\
&=\lim_{m\to\infty}\left|f_m(z)-f_n(z)\right|\\
&\le\epsilon
\end{align*}
$$

Therefore, $f_n\to f$ uniformly.

(전체적인 증명은 [Wikipedia : Weierstrauss M-test](https://en.wikipedia.org/wiki/Weierstrass_M-test)의 증명을 참고하였음.
ratio test를 두 번 쓸 필요가 있을까, 그러니까, 증명을 좀 간소화할 수 있을 것 같은데 어떻게 해야 할까, 잘 모르겠다.)

(b) Prove that $e^{z_1+z_2}=e^{z_1}e^{z_2}$

[refer to baby rudin 3.48, 3.50]

$$
\begin{align*}
e^{z_1}e^{z_2}
&=\sum_{n=0}^\infty\frac{~{z_1}^n}{n!}\sum_{n=0}^\infty\frac{~{z_2}^n}{n!}\\
&=\sum_{n=0}^\infty\sum_{k=0}^n\frac{~{z_1}^k}{k!}\frac{~{z_2}^{n-k}}{(n-k)!}\\
&=\sum_{n=0}^\infty\frac1{n!}\sum_{k=0}^n\binom nk{z_1}^k{z_2}^{n-k}\\
&=\sum_{n=0}^\infty\frac1{n!}(z_1+z_2)^n\\
&=e^{z_1+z_2}
\end{align*}
$$

(c) Derive Euler's identity.

Taylor's theorem aplied to sine and cosine yields

$$
\begin{align*}
\cos t = 1-\frac{t^2}{2!}+\frac{t^4}{4!}-\frac{t^6}{6!}+\cdots\\
\sin t = t-\frac{t^3}{3!}+\frac{t^5}{5!}-\frac{t^7}{7!}+\cdots\\
\end{align*}
$$

Plug in $x=0$ in the equation in (a) to get the Euler's identity ;

$$
\begin{align*}
e^{iy}
&=\sum_{n=0}^\infty\frac{(iy)^n}{n!}\\
&=1+iy-\frac{y^2}{2!}-\frac{iy^3}{3!}+\frac{y^4}{4!}+\frac{iy^5}{5!}-\cdots\\
&=\cos y + i\sin y.
\end{align*}
$$

(d) Prove that $e^{x+iy}=e^x(\cos y + i\sin y)$ and that $\lvert e^{x+iy}\rvert=e^x$

$$
\begin{gather*}
e^{x+iy}
=e^xe^{iy}
=e^x(\cos y + i\sin y)\\
\left|e^{x+iy}\right| = |e^x||\cos y+i\sin y|=e^x.
\end{gather*}
$$

(e) Prove that $e^z=1$ iff $z=2\pi ki$ for some integer $k$.

Put $z=x+iy$

$$
\begin{align*}
e^z=1
\iff&e^x=1\quad\land\quad \cos y+i\sin y = 1\\
\iff&x=0\quad\land\quad y=2\pi k\\
\iff&z = 2\pi ki
\end{align*}
$$

(f) Every complex number $z=x+iy$ can be written as $z=re^{i\theta}$ where $0\le r\lt\infty$.
$r$ is unique and $\theta$ is unique up to an integer multple of $2\pi$
Moreover, $r=|z|$ and $\theta=\arctan(y/x)$ if $x\ne0$.
 (omit)

(g) The transformation $z\mapsto ze^{i\theta}$ rotate $z$ counterclockwise by $\theta$ with respect to the origin.

(h) Put $y=\pm\theta$ to (c) $e^{iy}=\cos y + i\sin y$ to get

$$
\begin{align*}
\frac{e^{i\theta}+e^{-i\theta}}2&=\cos\theta\\
\frac{e^{i\theta}-e^{-i\theta}}{2i}&=\sin\theta
\end{align*}
$$

(i) Prove trigonometric identities ; 

$$
\begin{align*}
\sin(\theta+\phi)&=\sin\theta\cos\phi+\cos\theta\sin\phi\\
\sin(\theta-\phi)&=\sin\theta\cos\phi-\cos\theta\sin\phi\\
\cos(\theta+\phi)&=\cos\theta\cos\phi-\sin\theta\sin\phi\\
\cos(\theta-\phi)&=\cos\theta\cos\phi+\sin\theta\sin\phi\\
2\sin\theta\cos\phi&=\sin(\theta+\phi) + \sin(\theta-\phi)\\
2\cos\theta\sin\phi&=\sin(\theta+\phi) - \sin(\theta-\phi)\\
2\cos\theta\cos\phi&=\cos(\theta+\phi) + \cos(\theta-\phi)\\
2\sin\theta\sin\phi&=-\cos(\theta+\phi)+ \cos(\theta-\phi)\\
\end{align*}
$$

Since

$$
\begin{align*}
\cos(\theta+\phi)+i\sin(\theta+\phi)
=&e^{i(\theta+\phi)}\\
=&e^{i\theta}e^{i\phi}\\
=&(\cos\theta+i\sin\theta)(\cos\phi+i\sin\phi)\\
=&(\cos\theta\cos\phi-\sin\theta\sin\phi)
+i(\sin\theta\cos\phi+\cos\theta\sin\phi),
\end{align*}
$$

the third and the first identity follow.
Substituting $\phi$ by $-\phi$, the second and fourth ones follow.
Adding and substracting these four identities, the remaining identities follow.

### 3.5
Prove the followings, provided that $m$ and $n$ are integers. 

$$
\begin{align*}
(1)\quad&\text{The map }x\mapsto e^{inx}\text{ has period }2\pi.\\
(2)\quad&\frac1{2\pi}\int_{-\pi}^\pi e^{inx}\,dx=
\begin{cases}
0&(n\ne 0)\\1&(n=0)
\end{cases}\\
\\
(3)\quad&\frac1\pi\int_{-\pi}^\pi\cos nx\cos mx\,dx=
\begin{cases}
0&(n\ne m)\\1&(n=m)
\end{cases}\\
(4)\quad&\frac1\pi\int_{-\pi}^\pi\sin nx\sin mx\,dx=
\begin{cases}
0&(n\ne m)\\1&(n=m)
\end{cases}\\
(5)\quad&\frac1\pi\int_{-\pi}^\pi\sin nx\cos mx\,dx=0
\end{align*}
$$

((1)에서 문제가 잘못되었다. 주기는 $\frac{2\pi}n$이다.)

(1) Since $e^{inx}$ is a linear combination of periodic functions with period $\frac{2\pi}n$, it also has period $\frac{2\pi}n$.

(2) If $n=0$, then

$$
\frac1{2\pi}\int_{-\pi}^\pi e^{inx}\,dx
=\frac1{2\pi}\int_{-\pi}^\pi\,dx=1
$$

Otherwise,

$$
\begin{align*}
\frac1{2\pi}\int_{-\pi}^\pi e^{inx}\,dx
&=\frac1{2\pi}\int_{-\pi}^\pi\cos nx+i\sin nx\,dx\\
&=\frac1{2\pi}\int_{-\pi}^\pi\cos nx\,dx
+\frac i{2\pi}\int_{-\pi}^\pi\sin nx\,dx
\end{align*}
$$

Since the antiderivatives of $\sin nx$ and $\cos nx$ are both periodic with period $\frac{2\pi}n$, all the term vanishes.

(3) The left hand side equals to

$$
\frac1{2\pi}\int_{-\pi}^\pi\cos(n+m)x+\cos(n-m)x\,dx
$$

or

$$
\frac1{2\pi}\int_{-\pi}^\pi\cos(n+m)x\,dx
+\frac1{2\pi}\int_{-\pi}^\pi\cos(n-m)x\,dx
$$

The first integrand has always periodic antiderivative and thus the first term always vanishes.
The second integrand does too if $m\ne n$, while if $m=n$, the integrand is $1$ and the second term equals to 1

(4) Similarly, the left hand side in this case equals to

$$
-\frac1{2\pi}\int_{-\pi}^\pi\cos(n+m)x\,dx
+\frac1{2\pi}\int_{-\pi}^\pi\cos(n-m)x\.dx
$$

Again, the first term always vanishes and the second one equals $0$ if $m\ne n$ and $1$ if $m=n$.

(5) Similarly, the left hand side in this case equals to

$$
\frac1{2\pi}\int_{-\pi}^\pi\sin(n+m)x\,dx
+\frac1{2\pi}\int_{-\pi}^\pi\sin(n-m)x\,dx
$$

The first term always vanishes as before.
The second term does too if $m\ne n$, while if $m=n$, the integrand is $0$ and the second term also vanishes.
Thus the whole value always equals to 0.

### 3.6
Prove that the ODE

$$f''(t)+c^2f(t)=0$$

has the solution

$$f(t)=a\cos ct + b\sin ct.$$

The solution indeed satisfies the ODE by a simple calculation.
Conversely, suppose the ODE.
As presented in the hint, let

$$
\begin{align*}
g(t)&=f(t)\cos ct-c^{-1}f'(t)\sin ct\\
h(t)&=f(t)\sin ct+c^{-1}f'(t)\cos ct
\end{align*}
$$

Then,

$$
\begin{align*}
g'(t)
&=f'(t)\cos ct-cf(t)\sin ct-c^{-1}f''(t)\sin ct-f'(t)\cos ct\\
&=-cf(t)\sin ct+cf(t)\sin ct\\
&=0\\
h'(t)
&=f'(t)\sin ct+cf(t)\cos ct+c^{-1}f''(t)\cos ct-f'(t)\sin ct\\
&=cf(t)\cos ct-cf(t)\cos ct\\
&=0
\end{align*}
$$

Thus, $f(t)=a$ and $g(t)=b$ for some real $a$ and $b$.
In other words,

$$
\begin{align*}
a&=f(t)\cos ct-c^{-1}f'(t)\sin ct\\
b&=f(t)\sin ct+c^{-1}f'(t)\cos ct
\end{align*}
$$

Eliminating $f'(t)$ in these equation, we get

$$
a\cos ct + b\sin ct = f(t)\times(\cos^2ct+\sin^2ct)=f(t).
$$

### 3.7
If $a$ and $b$ are real,

$$a\cos ct+b\sin ct = A\cos(ct-\phi)$$

for some $A\ge0$ and $\phi\in[0,2\pi)$.

If $a=b=0$, let $A=0$.
Then the above equation holds for an arbitrary $\phi$.
Suppose that $a\ne0$ or $b\ne 0$.
Note that $P=\left(\frac a{\sqrt{a^2+b^2}}, \frac b{\sqrt{a^2+b^2}}\right)$ lies on the unit circle.
Let $\phi$ be the angle such that $P$ is obtained by rotating the point $(1,0)$ counterclockwise by $\phi$ with respect to the origin.
Then $\cos\phi = \frac a{\sqrt{a^2+b^2}}$ and $\sin\phi = \frac b{\sqrt{a^2+b^2}}$.
It follows that

$$
\begin{align*}
a\cos ct+b\sin ct
&=\sqrt{a^2+b^2}\left(\cos ct\cos\phi+\sin ct\sin\phi\right)\\
&=\sqrt{a^2+b^2}\cos(ct-\phi)
\end{align*}.
$$

### 3.8
([Asked at mathexchange](https://math.stackexchange.com/q/4980904/746048))

Suppose that $F:(a,b)\to\mathbb R$ has a continuous second derivative.
If $x$ and $x+h$ belongs to $(a,b)$, prove that

$$F(x+h)=F(x)+hF'(x)+\frac{h^2}2F''(x)+h^2\phi(h)$$

for some $\phi$ where

$$\lim_{h\to0}\phi(h)=0.$$

Moreover, prove that

$$\lim_{h\to0}\frac{F(x+h)+F(x-h)-2F(x)}{h^2}=F''(x).$$

(proof) Since $F'(x)$ is differentiable at $x$,

$$\lim_{k\to0}\frac{F'(x+k)-F'(x)}k = F''(x).$$

Let

$$
\psi(k)=
\begin{cases}
\frac{F'(x+k)-F'(x)}k - F''(x) &(k\ne0)\\
0&(k=0).
\end{cases}
$$

Then,

$$
\lim_{k\to0}\psi(k)=0
$$

and $\psi$ is continuous on $\mathbb R$.
Moreover, $F'(x+k)=F'(x)+kF''(x)+k\psi(k)$.
Denoting $k=y-x$, we have

$$
F'(y)=F'(x)+(y-x)F''(x)+(y-x)\psi(y-x).
$$

Then,

$$
\begin{align*}
F(x+h)
&=F(x)+\int_x^{x+h}F'(y)\,dy\\
&=F(x)+\int_x^{x+h}\left(F'(x)-xF''(x)\right)+yF''(x)+(y-x)\psi(y-x)\,dy\\
&=F(x)+\left(F'(x)-xF''(x)\right)h+F''(x)\left(xh+\frac12h^2\right)+\int_x^{x+h}(y-x)\psi(y-x)\,dy\\
&=F(x)+hF'(x)+\frac{h^2}2F''(x)+\int_x^{x+h}(y-x)\psi(y-x)\,dy.
\end{align*}
$$

Note that $\psi$ is (Riemann) integrable since it is continuous.

So I can take

$$
\phi(h)=\frac1{h^2}\int_x^{x+h}(y-x)\psi(y-x)\,dy
$$

It can be modified by the substitution rule ($y-x = u$) ;

$$\phi(h)=\frac1{h^2}\int_0^hu\psi(u)\,du$$

To prove that $\phi(h)\to0$ as $h\to0$, we can use one of the two calculation belows :

1. L'Hopital Rule:

$$
\lim_{h\to0}\phi(h)=\lim_{h\to0}\frac{h\psi(h)-0}{2h}=\frac12\lim_{h\to0}\psi(h)=0.
$$

2. $\epsilon$-$\delta$ reasoning :

Fix $\epsilon>0$.
Since $\psi(h)\to0$ as $h\to0$, there exists $\delta>0$ such that if $-\delta<u<\delta$, then $|\psi(u)|<\epsilon$.
If $-\delta<h<\delta$, then

$$
\begin{align*}
|\phi(h)|
&\le\frac1{h^2}\int_{-|h|}^{|h|}|u||\psi(u)|\,du\\
&\le\frac\epsilon{h^2}\int_{-|h|}^{|h|}|u|\,du\\
&=\epsilon.
\end{align*}
$$

Therefore, $\phi(h)\to0$ as $h\to0$ as desired.

Now to prove the second statement,
substitute $h$ by $-h$ to get

$$
\begin{align*}
F(x+h)&=F(x)+hF'(x)+\frac{h^2}2F''(x)+h^2\phi(h)\\
F(x-h)&=F(x)-hF'(x)+\frac{h^2}2F''(x)+h^2\phi(-h)
\end{align*}
$$

Then

$$
F(x+h)+F(x-h)-2F(x)=h^2F''(x)+h^2\phi(h)+h^2\phi(-h)
$$

and

$$
\lim_{h\to0}\frac{F(x+h)+F(x-h)-2F(x)}{h^2}
=\lim_{h\to0}\left(F''(x)+\phi(h)+\phi(-h)\right)=F''(x)
$$ 